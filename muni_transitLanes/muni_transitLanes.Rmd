---
title: "Analysis of Transit Only Lane Violations for SFMTA"
author: Anthony Chau
date: 07-10-2018
output: github_document
always_allow_html: yes
---

```{r, message=FALSE, results='hide'}
library(dplyr)
library(ggplot2)
library(stringr)
library(magrittr)
library(tidyverse)
library(leaflet)
library(plotly)
library(lubridate)
```


# Read in data
```{r read_data, results = 'hide'}
# Use read_csv from readr package (Faster, more reproducible, tibbles)
muni <- read_csv('muni_transitLanes.csv', trim_ws = TRUE, na = c("", "NA"))
muni <- as.data.frame(muni)

# Check variables in muni
# str(muni)
# summary(muni)

```
# Cleaning the Data

First, we remove the Citation.Issue.Month column from the data frame since the
month is already included in the Citation.Issue.Date column. And, we remove the 
Last.Edited.Date and Ticket Number column because the columns are not relevant for our analysis.
```{r remove_columns}

muni <- muni %>% 
  select(-`Citaton Issue Month`, -`Last Edited Date`, -`Ticket Number`)

```

## Missing Values

We have many missing values scattered across the columns in the muni data frame. More specifcally, there are missing values in the 'Amount Due', 'Suspend Code', 'Suspend Process Date', 'Suspend Until Date', 'Disposition Code', and 'Geom' columns.

we have many missing values in the Disposition Code column but few missing values for the 'Amount Due' and Geom' column. Also, there are about an equal amount of missing values for the 'Suspend Code', 'Suspend Process Date, and 'Suspend Until Date'. This makes sense intuitively because the columns are related to each other. In fact the 'Suspend Process Date' and 'Suspend Until Date' have the same number of missing values. 
```{r missing_values}
# Check for NA values for each column

apply(muni, 2, function(x) any(is.na(x)))

# find total number of missing values for columns with missing values
totalMissing <-  function(missing_column){
  cat("Total missing values:", sum(is.na(missing_column)), "\n")
}

totalMissing(muni$`Amount Due`)
totalMissing(muni$`Suspend Code`)
totalMissing(muni$`Suspend Process Date`)
totalMissing(muni$`Suspend Until Date`)
totalMissing(muni$`Disposition Code`)
totalMissing(muni$Geom)

```

## Impute Missing Valuess
```{r}

```


## Date and Time

Now, let's focus our attention on the date and time data within this dataset.

Initially, the citation issue date and time were stored as factor variables. We collapse date and time into a single column and convert it to a datetime object. This will make the data easier to work with in our analysis.
```{r dateTime}
# Convert all values in the original citation column into a Date object
muni$citation_date <- as.Date(muni$`Citation Issue Date`, format ="%m/%d/%Y")


# Combine date and time columns into a citation_dateTime column
muni <-  muni %>% 
  unite(citation_dateTime, `Citation Issue Date`, `Citation Issue Time`, sep = " ")

# Convert citation_dateTime to a POSIXct object
muni$citation_dateTime <- mdy_hms(muni$citation_dateTime)

```

## Separate date column

We also want to analyze citation counts in a smaller time frame, so we separate the citation_date column into three columns for the month, date, and year
```{r}
muni <- muni %>% 
  separate(citation_date, into = c("year", "month", "day"), sep = "-")
  
```

## Convert month, day, and year columns into the integer type
```{r}
muni$month <- as.integer(muni$month)

muni$day <- as.integer(muni$day)

muni$year <- as.integer(muni$year)
```


## Spatial Location 
```{r}
# Split Geom column into Longitude and Latitude column
muni <-  muni %>% 
  separate(Geom, into = c("latitude", "longitude"), sep = ",")

# Clean up longitude and latitude column (remove parenthesis)
muni$latitude <- muni$latitude %>% 
  str_replace("^\\(", "")

muni$longitude <-  muni$longitude %>% 
  str_replace("\\)$", "")

```


## Extract unique street names from location column 

We create a new column which consists of only the street name where the violation occured. In the original datset, the location column provided both the street number and street name. As a result, we have an extremely high amount of factor levels for the location column. Hence, we will condense down the number of factor levels to the total number of unique street names.
```{r street_names}

# Good functional programming practice:
# Not advisable to change global variables in functions
# Instead, we write a function with a more explicit return value and reassign the result
# outside the function (gloabl environment)

# In this case, we create a new column in data frame called y, which contains only the
# street names of all the location. We use the get_streetName function to return this
# column and then assign that column to a new column in the muni data frame.


# instead of do.call() use dplyr:: bind_rows()

get_streetName <-  function(location_column){
  location_column <- as.character(location_column) 
  splitLocation <- strsplit(location_column, "(?<=\\d)\\b", perl=T)
  y <- do.call(rbind, splitLocation)
  y <- as.data.frame(y)
  colnames(y) <- c("street_number", "street_name")
  return(y$street_name)
}

muni$street_name <- get_streetName(muni$Location)

# Check street names
unique(muni$street_name)


### Explanation of Function

# Split location into street number and street name
# Logic: If a word boundary is proceeded by a digit, split the word
# Create new matrix with street name column and street name column
# Change column names
# Make new column in muni df



```

## Clean up street names

In the newly created street_name column, we remove unnecessary puncation or white space within the different factor levels and remove the street type from each factor level. Lastly, we convert each street name to title style capitalization.
```{r}
# To extend practicality and to simplify our string data, any street type will be converted to empty string

# Vector of street types for use with str_replace_all function
street_types <- c("ST$" = "", "BLVD$" = "", "TUNL$" = "", "Street" = "", "AVE" = "",
                  "STREET$" = "")


clean_streetName <- function(streetName_column){
  streetName_column <- streetName_column %>% 
  as.character() %>% 
  str_replace_all("[:punct:]", "") %>% 
  str_replace_all(street_types) %>% 
  str_to_title() %>% 
  trimws(which = "both")
  return(streetName_column)
}

muni$street_name <- clean_streetName(muni$street_name)

# Take in original location column, which was previously cleaned up by the 

# Check
unique(muni$street_name)


```


## Clean up minor spelling mistakes

Some of the street names in the dataset are misspelled. We manually correct these
mistakes by reassigning observations with misspelling to the correct spelling.

For this analysis, I have decided to remove the street type indicator from non-duplicate
street names. Beacuse of this, only numerical street names, such as 4th or 22nd, have
street type indicators.
```{r}

# Clean up spelling and duplicates of street names
# Find more efficient way of doing this
# Only keep indicator of the street for the 'numerical streets' because San Francisco
# has both 2nd St and 2nd Ave
# Remove for the rest to keep it more clean
# We will determine the exact geographical location with longitude and latitude
# coordinates
muni$street_name[muni$street_name %in% c("Ofarrell", "Ofallell")] <- "O'Farrell"
muni$street_name[muni$street_name %in% c("4Th", "04Th", "O4th")] <- "4th St"
muni$street_name[muni$street_name %in% c("3Rd", "03Rd")] <- "3rd St"
muni$street_name[muni$street_name %in% c("22Nd")] <- "22nd St"
muni$street_name[muni$street_name %in% c("Po")] <- "Post"

# Change street_name to factor variable
muni$street_name <- factor(muni$street_name)

# Check
unique(muni$street_name)
```

## Rename columns
```{r}

muni <- muni %>% 
  rename(ID = "Object ID", violation_type = "Violation", location = "Location",
         fine_amount = "Fine Amount")

names(muni)

```


## Rearrange columns

```{r}
muni <- muni %>% 
  select(ID, month, day, year, street_name, 
         violation_type, latitude, longitude, 
         fine_amount, citation_dateTime, everything())
```


# Data Visualization

First, we summarize the number of citations per day by grouping the observations by each day. Then, we make a frequency plot with ggplot2 to display the distribution of citationc counts over time
```{r}
citations_dt <- muni %>% 
  select(street_name, citation_dateTime)

# Citation count by day from 2008 to 2014
citations_dt %>% 
  ggplot(aes(citation_dateTime)) +
  geom_freqpoly(binwidth = 86400) # 86400 secs = 1 day

# The above 


```

The above plot is too nosy. Let's plot out violation counts by month.
```{r warning= FALSE}
citations_dt %>% 
  ggplot(aes(citation_dateTime)) +
  # take average days in a month to be 30 and multiple by the number of seconds in a day
  geom_freqpoly(binwidth = 86400*30, color = "firebrick") +
  theme_minimal() +
  labs(x = "Date", y = "Citation Count", 
       title = "Transit Lane Violation Counts in San Francisco") +
  scale_x_datetime(date_breaks = "4 months") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, 
                                   margin = margin(0, 0, 15, 0)),
        plot.title = element_text(size = 15, face = "bold", 
                                  margin = margin(0, 0, 10, 0)))
```




## Exploring Transit Lane Violation Types
```{r}

# Rename violations
muni <- muni %>% 
  rename(violation_type = Violation)


# Counts of violation type
table(muni$violation_type)

unique(muni$violation_type)


```

# Delete violation type categories from data frame

We have low observations counts for the following categories of violations: 'NO VIOL', 'ON SIDEWLK', 'OVR 18" C', and 'PK FR LB'. So, we remove these categories and the unique observations to make out analysis cleaner.
```{r}
# Find the 8 observations with the 4 violation categories and delete them from data frame

muni <- muni[!muni$violation_type %in% c('NO VIOL', 'ON SIDEWLK', 'OVR 18 " C', 'PK FR LN'),]

# Check violation categories
table(muni$violation_type)

# Check total number of observations - we orignially had 17,178 observations
dim(muni)

```

# Combine small violation counts on different street names
```{r}

```


Work on this
```{r}

# Group together factor level with low counts

# Visualize number of violations by street name with barplot
streetBarPlot <- ggplot(data=muni, aes(x=street_name)) + 
  geom_bar(aes(fill=violation_type), color='black', position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

streetBarPlot
```

We find that most transit lane violations are concentrated on a few streets: Geary, Market, Mission, Folsom, Stockton, and Sutter. Almost all of these pass through downtown
San Francisco, which is plausible since many bus services aggregate in downtown. 

Many questions can be asked from this visualization. Is the high number of citations of these streets because of high bus and therefore high transit lane density in downtown San Francisco? 

Are drivers more likely to violate regulations in the downtown area because of how crowded and hectic streets can get during peak hours, which makes driver more 
short-tempered and willing to make shortcuts through transit lanes?

Or, are high incidence of transit lane violations on a few streets because muni drivers
are more short-tempered and willing to report violations in crowded downton SF?

Also, we have to take into account when each transit lane was implemented.



# Visualize number of violations with barplot
```{r}
# Visualize number of violations by street name with barplot
violations <- ggplot(data=muni, aes(x=violation_type)) + 
  geom_bar() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

violations
```

Most violation types are towaway zone and towaway zone #1. There are few observations of the on sidewalk, OVR 18*C violations, and no violation type. Need more information on how specific violation types are defined.


Violations - Count Plot
```{r}
violationsCountPlot <- ggplot(data=muni)+ 
  geom_count(mapping = aes(x = violation_type, y = street_name)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))


violationsCountPlot
```

Violations by Street Name - Tile Plot (possibly do a heat map with d3heatmap or heatmaply)

Most violation types were 'BUS ZONE', 'DBL PARK', and 'TWAWAY ZN#1'.
```{r}

muni %>% 
  count(violation_type, street_name) %>% 
  ggplot(mapping = aes(x = reorder(violation_type, n), y = street_name)) +
    geom_tile(aes(fill = n), color = 'white', size = 0.25) +
    scale_fill_continuous(type = "viridis", na.value = "grey90") +
    scale_x_discrete(limits = c('TWAWY ZN#1', 'DBL PARK', 'PRK PROHIB',
                                'BUS ZONE', 'TWAWY ZONE', 
                                'PK PHB OTD', 'TRNST ONLY')) +
    theme_grey() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, face = "bold"),
          plot.background = element_blank(),
          panel.border = element_blank())



```


Heatmap - Plotly
```{r}

# Create matrix of observation counts by street name and violation type
# Bug with matrix code
m <- table(muni$street_name, muni$violation_type)

p <- plot_ly(z = m,
  x = levels(muni$street_name), y = levels(muni$violation_type),
  type = "heatmap"
)

p
```



Violations - Pie Chart
```{r}
# Visualize number of violations with pie chart
pie <- ggplot(muni, aes(x = "", fill = factor(violation_type))) + 
  geom_bar(width = 1) +
  theme(axis.line = element_blank(), 
        plot.title = element_text(hjust=0.5)) + 
  labs(fill="class", 
       x=NULL, 
       y=NULL, 
       title="Pie Chart of Violation Type", 
       caption="Source: muni")
  
pie + coord_polar(theta = "y", start=0)

```

# Mapping Transit Lane Violations
```{r}
m <- leaflet() %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addMarkers(lng= c(-122.415269816, -121.34, -120.57), lat = c(37.7854374715, 37.85, 38.12), popup="Transit Violation", label= "Broke the law!")
m 
```





# Time Series visualization test
Account for dates with no citation
Make dates with sequence function between earliest date and latest date
try missing_values <- date[!date in% sequence]
```{r}
library(dplyr)

# Create new column which stores how many citations were issued that day and build 
# time series object from that column

# Convert citation date to date object to work in dplyr
muni$citation_date <- as.Date(muni$citation_date, format ='%m/%d/%Y')
muni$citation_dateTime <- as.Date(muni$citation_dateTime, format ='%m/%d/%Y  %H:%M') 


# Group and count observations by date 
muni <- 
  muni %>%
  arrange(citation_date) %>%
  group_by(citation_date) %>%
  mutate(citation_count = n())

# Try n = n()
# Count missing values: (sum(is.na(x))) or set na.rm=TRUE

# Pull out citation_count vector
citation_count <- 
  muni %>%
  pull(citation_count)

# Time series
# More research on dealing with regular data (almost daily) and spanning across
# many years
citation_ts <- ts(citation_count, frequency = 7, start= c(2008,2))

plot.ts(citation_ts)



```

